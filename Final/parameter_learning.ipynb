{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43b3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, torch\n",
    "\n",
    "device = \"cpu\"\n",
    "dtype  = torch.float64\n",
    "\n",
    "with open(\"model.json\", \"r\") as f:\n",
    "    model = json.load(f)\n",
    "\n",
    "# and whatever you used to build state_index, n_states, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab85854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "theta_teacher_loaded = torch.load(\"theta_teacher.pt\")  # or \"/mnt/data/theta_teacher.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4cd1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_teacher_loaded = {\n",
    "    name: val.to(device=device, dtype=dtype)\n",
    "    for name, val in theta_teacher_loaded.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3dc83fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterDict(\n",
       "    (rT_max): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_ET): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_ET): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_Tam_ERPR): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_Tam): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (rE_max): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (rH_max): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (delta_E): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (delta_H): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_T_to_E): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_Tstim_E): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_T_to_H): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_Tstim_H): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_H_to_E): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_Hboost_E): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (PDL1_basal): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_PDL1_up_T): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_PDL1_up_T): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_PDL1_up_E): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_PDL1_up_E): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_PDL1_decay): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_PDL1): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (n_PDL1): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (phi_PD): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_IO_block_PDL1): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_T_secrete_TGFb): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_TGFb_decay): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_TGFb): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (n_TGFb): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (phi_TGFb): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_IO): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (n_IO): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (gamma_IO): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (Emax_Adr): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (EC50_Adr): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (n_Adr): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (Emax_Cyc): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (EC50_Cyc): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (n_Cyc): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (Emax_Tax): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (EC50_Tax): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (n_Tax): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_N_prolif): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (sN): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (dN): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (qT): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (qE): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_N): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (n_N): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_N_use_T): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_N_use_E): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (chi_N_chemo): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (sBM): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (dBM): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (qBM_chemo): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_BM): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (n_BM): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (gamma_BM_IO): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (gamma_BM_TIL): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (K_TIL): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (p_ct): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_ctclr): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (lambda_Adr): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (lambda_Cyc): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (lambda_Tax): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (lambda_Tam): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (lambda_IO): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (lambda_TIL): Parameter containing: [torch.DoubleTensor of size ]\n",
       "    (k_PDboost_T): Parameter containing: [torch.DoubleTensor of size ]\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base \"true\" parameters used to generate x_data (teacher)\n",
    "theta_true = theta_teacher_loaded   # <---- use the loaded dict, not theta_teacher\n",
    "\n",
    "# Create learnable copy with ~10% multiplicative noise\n",
    "theta_learn = torch.nn.ParameterDict()\n",
    "\n",
    "noise_level = 0.10  # 10% noise\n",
    "\n",
    "for name, val in theta_true.items():\n",
    "    # Only make learnable if it's in the \"learnable\" group from model.json\n",
    "    if name in model[\"parameters_fit_groups\"][\"learnable\"]:\n",
    "        v0 = val.clone().detach().to(device=device, dtype=dtype)\n",
    "        noise = noise_level * torch.randn_like(v0)\n",
    "        init_val = v0 * (1.0 + noise)\n",
    "        theta_learn[name] = torch.nn.Parameter(init_val)\n",
    "    else:\n",
    "        # keep fixed params as plain tensors\n",
    "        theta_learn[name] = val.clone().detach().to(device=device, dtype=dtype)\n",
    "\n",
    "theta_learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d19e5b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m fit_state_names = [\u001b[33m\"\u001b[39m\u001b[33mT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mctDNA\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m state_mask = torch.ones(\u001b[32m1\u001b[39m, \u001b[43mn_states\u001b[49m, dtype=dtype, device=device)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m fit_state_names:\n\u001b[32m      5\u001b[39m     idx = state_index[s]\n",
      "\u001b[31mNameError\u001b[39m: name 'n_states' is not defined"
     ]
    }
   ],
   "source": [
    "fit_state_names = [\"T\", \"ctDNA\"]\n",
    "\n",
    "state_mask = torch.ones(1, n_states, dtype=dtype, device=device)\n",
    "for s in fit_state_names:\n",
    "    idx = state_index[s]\n",
    "    state_mask[0, idx] = 1.0\n",
    "\n",
    "state_mask\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
